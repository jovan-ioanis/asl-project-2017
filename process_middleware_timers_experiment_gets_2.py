"""
     ASL project - fall 2017

        author: Jovan Nikolic

        Processes logs generated by middleware
"""
import numpy as np
import csv
import math


class TimerStruct:
    def __init__(self):
        self.worker_id = -1
        self.command = "none"
        self.number_of_keys = -1
        self.queue_size = -1
        self.request_received_time = -1
        self.put_in_queue_time = -1
        self.taken_out_of_queue_time = -1
        self.sent_to_server_time = -1
        self.received_complete_response_time = -1
        self.response_sent_to_client_time = -1
        self.dump_to_disk_flag = -1

path_base_sets = "data/experiment_gets/middleware"
path_base_gets = "data/experiment_gets/middleware"
agg_path_base = "aggregated_data/experiment_gets/timers_2/"
client_threads_basename = "clientThreads_"
worker_threads_basename = "_workerThreads_"
counters_basename = "counter_"
timers_basename = "timers_"

number_of_middlewares = 2
cpt = 2
wt = 64
num_keys = [1, 3, 6, 9]
suffixes = ["sharded", "nonsharded"]
metrics = ["mean", "std"]
command_types = ["_S0-G10"]
repetitions = 3
step = 1e9


def print_csv(header, path, full_data):
    print("Header length is: " + str(len(header)))
    print("Full data 1st dim length is: " + str(len(full_data)))
    print("Full data 2nd dim lengths are: " + str(len(full_data[0])) + " " + str(len(full_data[1])) + " " + str(
        len(full_data[2])))
    with open(path, 'w') as csv_file:
        writer = csv.DictWriter(csv_file, fieldnames=header)
        writer.writeheader()

        for row in range(len(full_data[0])):
            one_row = {}
            for i in range(len(header)):
                one_row[header[i]] = full_data[i][row]
            writer.writerow(one_row)
        csv_file.close()


def read_one_experiment(current_mw, keys, index, rep, command_type):

    raw_data = []
    base_p = path_base_gets

    base_path = base_p + str(current_mw) + "/" + \
                client_threads_basename + str(cpt) + \
                worker_threads_basename + str(wt) + \
                command_type + \
                "_rep" + str(rep + 1) + "_" + suffixes[index] + "_keys" + str(keys) + "/logs/"

    for current_num_workers in range(wt):
        path = base_path + timers_basename + str(current_num_workers) + ".log"

        with open(path, 'r') as timer_file:
            timer_data = timer_file.readlines()
            if len(timer_data) == 0:
                print(" Missing data for: cpt = " + str(cpt) + ", wt = " + str(wt) + ", rep = " + str(rep))
                continue
            timer_data = [x.strip() for x in timer_data]
            for k, line in enumerate(timer_data):
                if k == 0:
                    continue
                parsed_line = line.split(',')
                [x.strip() for x in parsed_line]
                ts = TimerStruct()
                ts.worker_id = int(parsed_line[0])
                ts.command = parsed_line[1]
                ts.number_of_keys = int(parsed_line[2])
                ts.queue_size = int(parsed_line[3])
                ts.request_received_time = int(parsed_line[4])
                ts.put_in_queue_time = int(parsed_line[5])
                ts.taken_out_of_queue_time = int(parsed_line[6])
                ts.sent_to_server_time = int(parsed_line[7])
                ts.received_complete_response_time = int(parsed_line[8])
                ts.response_sent_to_client_time = int(parsed_line[9])
                ts.dump_to_disk_flag = int(parsed_line[10])

                raw_data.append(ts)

    # here we have all requests that went through the middleware for one fixed config and rep.

    #####################
    # PROCESSING:
    #####################

    sorted_rrt = sorted(raw_data, key=lambda x: x.request_received_time, reverse=False)

    start_time = sorted_rrt[0].request_received_time
    finish_time = start_time + step
    beginning_of_time = start_time

    response_times = []
    net_thread_processing_time = []
    waiting_in_queue_time = []
    worker_preprocessing_time = []
    server_service_time = []
    worker_postprocessing_time = []
    queue_size_time = []

    res_t = []
    net_thread_processing_t = []
    waiting_in_queue_t = []
    worker_preprocessing_t = []
    server_service_t = []
    worker_postprocessing_t = []
    queue_size_t = []

    counter = 0

    for i, rec in enumerate(sorted_rrt):
        if rec.command != "GET":
            # print("COMMANDS DON'T MATCH!")
            continue
        if rec.request_received_time == -1:
            print("SOMETHING IS WRONG WITH TIME STRUCT!")
        if start_time <= rec.request_received_time < finish_time and i < len(sorted_rrt) - 1:

            res_t.append(abs(rec.response_sent_to_client_time - rec.request_received_time) / 1e6)
            net_thread_processing_t.append(abs(rec.put_in_queue_time - rec.request_received_time) / 1e6)
            waiting_in_queue_t.append(abs(rec.taken_out_of_queue_time - rec.put_in_queue_time) / 1e6)
            worker_preprocessing_t.append(abs(rec.sent_to_server_time - rec.taken_out_of_queue_time) / 1e6)
            server_service_t.append(abs(rec.received_complete_response_time - rec.sent_to_server_time) / 1e6)
            worker_postprocessing_t.append(abs(rec.response_sent_to_client_time - rec.received_complete_response_time) / 1e6)
            queue_size_t.append(rec.queue_size)

        else:

            if i == len(sorted_rrt) - 1:
                res_t.append(abs(rec.response_sent_to_client_time - rec.request_received_time) / 1e6)
                net_thread_processing_t.append(abs(rec.put_in_queue_time - rec.request_received_time) / 1e6)
                waiting_in_queue_t.append(abs(rec.taken_out_of_queue_time - rec.put_in_queue_time) / 1e6)
                worker_preprocessing_t.append(abs(rec.sent_to_server_time - rec.taken_out_of_queue_time) / 1e6)
                server_service_t.append(abs(rec.received_complete_response_time - rec.sent_to_server_time) / 1e6)
                worker_postprocessing_t.append(abs(rec.response_sent_to_client_time - rec.received_complete_response_time) / 1e6)
                queue_size_t.append(rec.queue_size)

            a = np.mean(np.asarray(res_t))
            if math.isnan(a):
                a = 0.0
            response_times.append(a)
            a = np.mean(np.asarray(net_thread_processing_t))
            if math.isnan(a):
                a = 0.0
            net_thread_processing_time.append(a)
            a = np.mean(np.asarray(waiting_in_queue_t))
            if math.isnan(a):
                a = 0.0
            waiting_in_queue_time.append(a)
            a = np.mean(np.asarray(worker_preprocessing_t))
            if math.isnan(a):
                a = 0.0
            worker_preprocessing_time.append(a)
            a = np.mean(np.asarray(server_service_t))
            if math.isnan(a):
                a = 0.0
            server_service_time.append(a)
            a = np.mean(np.asarray(worker_postprocessing_t))
            if math.isnan(a):
                a = 0.0
            worker_postprocessing_time.append(a)
            a = np.mean(np.asarray(queue_size_t))
            if math.isnan(a):
                a = 0.0
            queue_size_time.append(a)

            counter += 1

            res_t = []
            net_thread_processing_t = []
            waiting_in_queue_t = []
            worker_preprocessing_t = []
            server_service_t = []
            worker_postprocessing_t = []
            queue_size_t = []

            start_time = finish_time
            finish_time = start_time + step

    return counter, response_times, net_thread_processing_time, waiting_in_queue_time, worker_preprocessing_time, server_service_time, worker_postprocessing_time, queue_size_time, beginning_of_time


def main():
    for mw in range(number_of_middlewares):
        print("MW = " + str(mw))
        current_mw = mw + 1
        for index, suffix in enumerate(suffixes):
            print("   " + suffix)
            for key in num_keys:
                print("      keys = " + str(key))
                a1, b1, c1, d1, e1, f1, g1, h1, i1 = read_one_experiment(current_mw, key, index, 0, command_types[0])
                a2, b2, c2, d2, e2, f2, g2, h2, i2 = read_one_experiment(current_mw, key, index, 1, command_types[0])
                a3, b3, c3, d3, e3, f3, g3, h3, i3 = read_one_experiment(current_mw, key, index, 2, command_types[0])

                num_columns = min(a1, a2, a3)
                step_time = list(range(0, num_columns))

                bot1 = []
                bot2 = []
                bot3 = []
                for i in range(len(step_time)):
                    bot1.append(i1)
                    bot2.append(i2)
                    bot3.append(i3)

                final_agg_path = agg_path_base + "timer_aggregated_data_" + \
                                 "mw_" + str(current_mw) + \
                                 client_threads_basename + str(cpt) + \
                                 worker_threads_basename + str(wt) + \
                                 "_" + suffix + "_keys" + str(key) + ".csv"

                merged_data = [step_time, bot1, bot2, bot3, b1, b2, b3, c1, c2, c3, d1, d2, d3, e1, e2, e3, f1, f2, f3,
                               g1, g2, g3, h1, h2, h3]
                # merged_data = [step_time, bot1, b1, c1, d1, e1, f1, g1, h1]
                header = ["Time [s]"]
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Beginning of Time Timestamp - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Response Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean NetThread Processing Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Waiting in Queue Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Worker Pre-Processing Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Server Service Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Worker Post-Processing Time [s] - rep" + str(current_rep))
                for rep in range(repetitions):
                    current_rep = rep + 1
                    header.append("Mean Queue Size - rep" + str(current_rep))

                print_csv(header, final_agg_path, merged_data)


if __name__ == "__main__":
    main()